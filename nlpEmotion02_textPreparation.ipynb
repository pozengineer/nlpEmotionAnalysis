{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4b80834",
   "metadata": {},
   "source": [
    "## Mini Project 03- NLP Emotions: Text Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24dbe8a",
   "metadata": {},
   "source": [
    "Dataset:\n",
    "- A. Tripathi, \"Emotion Classification NLP\", Kaggle.com, 2021. [Online]. Available: https://www.kaggle.com/datasets/anjaneyatripathi/emotion-classification-nlp. [Accessed: 16- Jul- 2022]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bbcfb7",
   "metadata": {},
   "source": [
    "Sources:\n",
    "- WASSA-2017 Shared Task on Emotion Intensity. Saif M. Mohammad and Felipe Bravo-Marquez. In Proceedings of the EMNLP 2017 Workshop on Computational Approaches to Subjectivity, Sentiment, and Social Media (WASSA), September 2017, Copenhagen, Denmark.\n",
    "BibTex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af4b61b",
   "metadata": {},
   "source": [
    "Emotion Labels:\n",
    "- joy: 1\n",
    "- sadness: 2\n",
    "- anger: 3\n",
    "- fear: 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1e910c",
   "metadata": {},
   "source": [
    "### Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "00832850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install pipline\n",
    "# ! pip install simple-colors\n",
    "# ! pip install neattext\n",
    "# ! pip install emoji "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2394ce",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "60aea9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re as regex\n",
    "import spacy\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "import string\n",
    "from collections import Counter\n",
    "import re as regex\n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "import neattext.functions as nfx\n",
    "import nltk\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d7f77d",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "120f8157",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfData = pd.read_csv(\"textDataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "56222163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Just got back from seeing @GaryDelaney in Burs...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Oh dear an evening of absolute hilarity I don'...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Been waiting all week for this game ‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è #ch...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>@gardiner_love : Thank you so much, Gloria! Yo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>I feel so blessed to work with the family that...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  label\n",
       "0           0  Just got back from seeing @GaryDelaney in Burs...      1\n",
       "1           1  Oh dear an evening of absolute hilarity I don'...      1\n",
       "2           2  Been waiting all week for this game ‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è #ch...      1\n",
       "3           3  @gardiner_love : Thank you so much, Gloria! Yo...      1\n",
       "4           4  I feel so blessed to work with the family that...      1"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f9b1128e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfData.drop(['Unnamed: 0'], axis= 1, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "80b231f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7102, 2)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfData.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb96013",
   "metadata": {},
   "source": [
    "### Prepare the Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9d8a8953",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af24ab26",
   "metadata": {},
   "source": [
    "### Prepare the text\n",
    "All the text handling and preparation concerned with the changes and modifications from the raw source text to a format that will be used for the actual processing, things like:\n",
    "- handle encoding\n",
    "- handle extraneous and international charaters\n",
    "- handle symbols\n",
    "- handle metadata and embedded information\n",
    "- handle repetitions (such multiple spaces or newlines)\n",
    "\n",
    "Clean text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17aafff",
   "metadata": {},
   "source": [
    "### Text Handling on Single cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9a2db99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # reduce multiple spaces and newlines to only one\n",
    "    text = regex.sub(r'(\\s\\s+|\\n\\n+)', r'\\1', text)\n",
    "    # remove double quotes\n",
    "    text = regex.sub(r'\"', '', text)\n",
    "    text = regex.sub(r'(\\\\n)', ' ', text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0e0de06d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm so excited to see Nat tonight üòçüòç.. And how happy and cheery she is! &amp; then I'm even more excited for her to get on social media üòç #BB18\""
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demoText= dfData.iloc[4122, 0]\n",
    "# demoText= dfData.iloc[4321, 0]\n",
    "# demoText= dfData.iloc[3085, 0]\n",
    "# demoText= dfData.iloc[3023, 0]\n",
    "demoText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "33172395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm so excited to see Nat tonight üòçüòç.. And how happy and cheery she is! &amp; then I'm even more excited for her to get on social media üòç #BB18\""
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanStg01= clean_text(demoText)\n",
    "cleanStg01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d095a13c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for duplicate entries\n",
    "dfData.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "de9c9843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d22f12f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from emoji import demojize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ff827a19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm so excited to see Nat tonight üòçüòç.. And how happy and cheery she is! &amp; then I'm even more excited for her to get on social media üòç #BB18\""
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove userhandles\n",
    "text_userHandles= nfx.remove_userhandles(cleanStg01)\n",
    "text_userHandles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c041cf2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"i'm so excited to see nat tonight üòçüòç.. and how happy and cheery she is! &amp; then i'm even more excited for her to get on social media üòç #bb18\""
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lower casing\n",
    "text_lower= str.lower(text_userHandles)\n",
    "text_lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "864004d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"i'm so excited to see nat tonight :smiling_face_with_heart-eyes::smiling_face_with_heart-eyes:.. and how happy and cheery she is! &amp; then i'm even more excited for her to get on social media :smiling_face_with_heart-eyes: #bb18\""
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# handle emojis\n",
    "text_emoji= demojize(text_lower)\n",
    "text_emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "646f39ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove puntuation\n",
    "# punc_to_remove = string.punctuation\n",
    "\n",
    "# def remove_punctuation(text):\n",
    "#     return text.translate(str.maketrans('','', punc_to_remove))\n",
    "# text_punc= remove_punctuation(text_emoji)\n",
    "# text_punc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "90be5ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removae of punctuation\n",
    "# def remove_punc(text):\n",
    "#     pattern= regex.compile('[^\\w]+')\n",
    "#     init= regex.split(pattern, text)\n",
    "    \n",
    "#     output02= ' '.join(regex.split(pattern, text))\n",
    "# #     print(init)\n",
    "# #     print(output02)\n",
    "#     return output02\n",
    "\n",
    "# text_punc= remove_punc(text_emoji)\n",
    "# text_punc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c28da94e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i m so excited to see nat tonight smiling face with heart eyes smiling face with heart eyes and how happy and cheery she is amp then i m even more excited for her to get on social media smiling face with heart eyes bb18'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove punctuation\n",
    "def remove_punc(text):\n",
    "#     text= regex.sub(r'(\\b\\S{1}\\b)|(\\b\\S{2}\\b)', '', text)\n",
    "#     text= regex.sub(r'(\\b\\S{1}\\b)', '', text)\n",
    "#     tweet = regex.sub('http.*\\s', ' ', tweet)  # remove URLs\n",
    "#     tweet = regex.sub(r'\\bRT\\b|\\bcc\\b', '', tweet)  # remove RT and cc\n",
    "#     tweet = regex.sub('rs.*', '', tweet)  # remove hashtags\n",
    "#     tweet = regex.sub(r'\\bTheNextWeb\\b', '', tweet)  # remove mentions\n",
    "    text = regex.sub(r'[^\\w\\s]+|[_\\s]', ' ', text)  # remove punctuations\n",
    "    text= regex.sub('\\s+', ' ', text)  # remove extra whitespace\n",
    "    text= regex.sub('', '', text)  # remove extra whitespace\n",
    "    return text\n",
    "\n",
    "text_punc= remove_punc(text_emoji)\n",
    "text_punc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9526f4fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'excited see nat tonight smiling face heart eyes smiling face heart eyes happy cheery amp even excited get social media smiling face heart eyes bb18'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove stopwords\n",
    "STOPWORDS = set(stopwords.words(\"english\"))\n",
    "\n",
    "def remove_stopword(text):\n",
    "    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n",
    "text_stop= remove_stopword(text_punc)\n",
    "text_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3584030a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'m excited nat tonight smiling face heart eyes smiling face heart eyes happy cheery amp m excited social media smiling face heart eyes bb18'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stopWord_remove(cell):\n",
    "    doc= nlp(cell)\n",
    "    filtered_text =[] \n",
    "    token_list = []\n",
    "    for token in doc:\n",
    "        token_list.append(token.text)\n",
    "    for word in token_list:\n",
    "        lexeme = nlp.vocab[word]\n",
    "        if lexeme.is_stop == False:\n",
    "            filtered_text.append(word)\n",
    "#     print(f\"Token list: \\n{token_list}\")\n",
    "#     print(f\"\\nFiltered text: \\n{filtered_text}\")\n",
    "    joinFiltered= ' '.join(filtered_text)\n",
    "\n",
    "    pattern= regex.compile('[^\\w]+')\n",
    "    init01= regex.split(pattern, joinFiltered)\n",
    "\n",
    "    cleanFiltered= ' '.join(regex.split(pattern, joinFiltered))\n",
    "#     print(init01)\n",
    "#     print(cleanFiltered)\n",
    "    return cleanFiltered\n",
    "\n",
    "text_stop01= stopWord_remove(text_punc)\n",
    "text_stop01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "356eedb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'m excite nat tonight smile face heart eye smile face heart eye happy cheery amp m excite social medium smile face heart eye bb18'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "wordnet_map={\"N\":wordnet.NOUN, \"V\":wordnet.VERB, \"J\":wordnet.ADJ, \"R\":wordnet.ADV}\n",
    "\n",
    "def lemmatized_words(text):\n",
    "    pos_tagged_text = nltk.pos_tag(text.split())\n",
    "    return \" \".join([lemmatizer.lemmatize(word , wordnet_map.get(pos[0], wordnet.NOUN)) for word, pos in pos_tagged_text])\n",
    "    \n",
    "text_lemma= lemmatized_words(text_stop01)\n",
    "text_lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e99c9840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'m excite nat tonight smile face heart eye smile face heart eye happy cheery amp m excite social medium smile face heart eye bb '"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removal of numbers\n",
    "def remove_num(text):\n",
    "    pattern= regex.compile('[\\d]+')\n",
    "    init= regex.split(pattern, text)\n",
    "\n",
    "    output02= ' '.join(regex.split(pattern, text))\n",
    "#     print(init)\n",
    "#     print(output02)\n",
    "    return output02\n",
    "\n",
    "text_num= remove_num(text_lemma)\n",
    "text_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d97402c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'excite nat tonight smile face heart eye smile face heart eye happy cheery amp excite social medium smile face heart eye'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove single letter in text\n",
    "# text01= 'i am excited to go to a ocean'\n",
    "def remove_single(text):\n",
    "    text= regex.sub(r'(\\b\\S{1}\\b)|(\\b\\S{2}\\b)', '', text)\n",
    "#     text= regex.sub(r'(\\b\\S{1}\\b)', '', text)\n",
    "#     tweet = regex.sub('http.*\\s', ' ', tweet)  # remove URLs\n",
    "#     tweet = regex.sub(r'\\bRT\\b|\\bcc\\b', '', tweet)  # remove RT and cc\n",
    "#     tweet = regex.sub('rs.*', '', tweet)  # remove hashtags\n",
    "#     tweet = regex.sub(r'\\bTheNextWeb\\b', '', tweet)  # remove mentions\n",
    "#     tweet = regex.sub('[^\\w\\s]', '', tweet)  # remove punctuations\n",
    "    text= regex.sub('\\s+', ' ', text)  # remove extra whitespace\n",
    "    text= regex.sub(r'^\\s+|\\s+$', '', text)  # remove extra whitespace beginning and end of string\n",
    "    text= regex.sub('[o]{3,}', 'o', text)  # remove extra whitespace beginning and end of string\n",
    "    return text\n",
    "\n",
    "text_letter= remove_single(text_num)\n",
    "text_letter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299e35fc",
   "metadata": {},
   "source": [
    "### Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "be7aafc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_text(cell):\n",
    "    cleanStg01= clean_text(cell)\n",
    "    text_userHandles= nfx.remove_userhandles(cleanStg01)\n",
    "    text_lower= str.lower(text_userHandles)\n",
    "    text_emoji= demojize(text_lower)\n",
    "    text_punc= remove_punc(text_emoji)\n",
    "    text_stop01= stopWord_remove(text_punc)\n",
    "    text_lemma= lemmatized_words(text_stop01)\n",
    "    text_num= remove_num(text_lemma)\n",
    "    text_letter= remove_single(text_num)\n",
    "    return text_letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ac4489b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 58.9 s\n",
      "Wall time: 58.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Initialise some columns for feature's counts\n",
    "dfData['short']= dfData['text'].apply(lambda x: convert_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c9475bbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>short</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5806</th>\n",
       "      <td>Panpiper playing Big River outside The Bridges...</td>\n",
       "      <td>3</td>\n",
       "      <td>panpiper play big river outside bridge outrage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>@p4pictures it would be great but what if the ...</td>\n",
       "      <td>4</td>\n",
       "      <td>great card crash face scream fear happen twice...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>If purging was real, Kenya would be the countr...</td>\n",
       "      <td>4</td>\n",
       "      <td>purge real kenya country elite purge chopper l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>What a #lively #lovely #shower üòá ..</td>\n",
       "      <td>1</td>\n",
       "      <td>lively lovely shower smile face halo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6244</th>\n",
       "      <td>I'd pay good money to watch someone slap that ...</td>\n",
       "      <td>3</td>\n",
       "      <td>pay good money watch slap pout candice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5278</th>\n",
       "      <td>@MLB @JoeyBats19 Sam Dyson is probably having ...</td>\n",
       "      <td>4</td>\n",
       "      <td>sam dyson probably have flashback right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5944</th>\n",
       "      <td>jelly baby is my favourite insult</td>\n",
       "      <td>3</td>\n",
       "      <td>jelly baby favourite insult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2930</th>\n",
       "      <td>i is sad</td>\n",
       "      <td>2</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>@palmtreesarah @WorthingTheatre had more fun t...</td>\n",
       "      <td>1</td>\n",
       "      <td>fun funny person funsville hilarity usual than...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6770</th>\n",
       "      <td>Too many are on their 'yeah, the thing going o...</td>\n",
       "      <td>2</td>\n",
       "      <td>yeah thing cop shoot innocent people sad backy...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label  \\\n",
       "5806  Panpiper playing Big River outside The Bridges...      3   \n",
       "868   @p4pictures it would be great but what if the ...      4   \n",
       "1198  If purging was real, Kenya would be the countr...      4   \n",
       "55                  What a #lively #lovely #shower üòá ..      1   \n",
       "6244  I'd pay good money to watch someone slap that ...      3   \n",
       "5278  @MLB @JoeyBats19 Sam Dyson is probably having ...      4   \n",
       "5944                  jelly baby is my favourite insult      3   \n",
       "2930                                           i is sad      2   \n",
       "40    @palmtreesarah @WorthingTheatre had more fun t...      1   \n",
       "6770  Too many are on their 'yeah, the thing going o...      2   \n",
       "\n",
       "                                                  short  \n",
       "5806     panpiper play big river outside bridge outrage  \n",
       "868   great card crash face scream fear happen twice...  \n",
       "1198  purge real kenya country elite purge chopper l...  \n",
       "55                 lively lovely shower smile face halo  \n",
       "6244             pay good money watch slap pout candice  \n",
       "5278            sam dyson probably have flashback right  \n",
       "5944                        jelly baby favourite insult  \n",
       "2930                                                sad  \n",
       "40    fun funny person funsville hilarity usual than...  \n",
       "6770  yeah thing cop shoot innocent people sad backy...  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfData.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4f2f0e83",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Ok, it seems there is still hope in BSNL üôÇ\\\\nNow, BB speed is ok üôÇ\\\\nBut I won't thank and elate much lest it be gone again like before üòêüôÇ\""
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfData.iloc[4321, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0cd2addc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hope bsnl slightly smile face speed slightly smile face win thank elate like neutral face slightly smile face'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfData.iloc[4321, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a69372d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = Path('convertedTextDataset.csv')  \n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "dfData.to_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ca95aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
